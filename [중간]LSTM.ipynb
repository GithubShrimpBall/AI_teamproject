{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Multiply, Add\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/malicious_phish_CSV.csv'\n",
        "data = pd.read_csv(file_path, header=None, names=['url', 'type'])\n",
        "\n",
        "train_data, temp_data = train_test_split(data, test_size=0.4, random_state=42, stratify=data['type'])\n",
        "\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['type'])\n",
        "\n",
        "\n",
        "urls = train_data['url']\n",
        "labels = train_data['type']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(labels)\n",
        "\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(urls)\n",
        "X_train = tokenizer.texts_to_sequences(urls)\n",
        "X_train = pad_sequences(X_train, maxlen=300)\n",
        "\n",
        "X_val = tokenizer.texts_to_sequences(val_data['url'])\n",
        "X_val = pad_sequences(X_val, maxlen=300)\n",
        "y_val = label_encoder.transform(val_data['type'])\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(test_data['url'])\n",
        "X_test = pad_sequences(X_test, maxlen=300)\n",
        "y_test = label_encoder.transform(test_data['type'])\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=300),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(32, return_sequences=False),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#10,32\n",
        "#history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "#10,64\n",
        "#history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val))\n",
        "\n",
        "#10,128\n",
        "#history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_val, y_val))\n",
        "\n",
        "#20,32\n",
        "#history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "#20,64\n",
        "#history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_val, y_val))\n",
        "\n",
        "\n",
        "#20,128\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_val, y_val))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLs2yezEWDk9",
        "outputId": "1c0f5109-26c9-47bf-8d3b-5c0ff5342198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 27ms/step - accuracy: 0.8314 - loss: 0.4742 - val_accuracy: 0.9268 - val_loss: 0.2131\n",
            "Epoch 2/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 26ms/step - accuracy: 0.9363 - loss: 0.1889 - val_accuracy: 0.9513 - val_loss: 0.1504\n",
            "Epoch 3/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.9572 - loss: 0.1339 - val_accuracy: 0.9590 - val_loss: 0.1284\n",
            "Epoch 4/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.9649 - loss: 0.1107 - val_accuracy: 0.9698 - val_loss: 0.0952\n",
            "Epoch 5/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.9696 - loss: 0.0943 - val_accuracy: 0.9716 - val_loss: 0.0895\n",
            "Epoch 6/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9734 - loss: 0.0838 - val_accuracy: 0.9753 - val_loss: 0.0793\n",
            "Epoch 7/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 26ms/step - accuracy: 0.9762 - loss: 0.0749 - val_accuracy: 0.9773 - val_loss: 0.0729\n",
            "Epoch 8/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0699 - val_accuracy: 0.9787 - val_loss: 0.0686\n",
            "Epoch 9/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9793 - loss: 0.0647 - val_accuracy: 0.9786 - val_loss: 0.0681\n",
            "Epoch 10/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 26ms/step - accuracy: 0.9810 - loss: 0.0595 - val_accuracy: 0.9791 - val_loss: 0.0662\n",
            "Epoch 11/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9824 - loss: 0.0556 - val_accuracy: 0.9803 - val_loss: 0.0640\n",
            "Epoch 12/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0527 - val_accuracy: 0.9797 - val_loss: 0.0658\n",
            "Epoch 13/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 26ms/step - accuracy: 0.9842 - loss: 0.0498 - val_accuracy: 0.9798 - val_loss: 0.0660\n",
            "Epoch 14/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.9847 - loss: 0.0479 - val_accuracy: 0.9816 - val_loss: 0.0621\n",
            "Epoch 15/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9853 - loss: 0.0462 - val_accuracy: 0.9819 - val_loss: 0.0597\n",
            "Epoch 16/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.9863 - loss: 0.0429 - val_accuracy: 0.9819 - val_loss: 0.0604\n",
            "Epoch 17/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.9868 - loss: 0.0411 - val_accuracy: 0.9811 - val_loss: 0.0635\n",
            "Epoch 18/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 27ms/step - accuracy: 0.9871 - loss: 0.0402 - val_accuracy: 0.9804 - val_loss: 0.0642\n",
            "Epoch 19/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.9878 - loss: 0.0375 - val_accuracy: 0.9817 - val_loss: 0.0615\n",
            "Epoch 20/20\n",
            "\u001b[1m3053/3053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9885 - loss: 0.0361 - val_accuracy: 0.9815 - val_loss: 0.0624\n",
            "\u001b[1m4070/4070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10ms/step - accuracy: 0.9813 - loss: 0.0614\n",
            "Test Accuracy: 98.11%\n"
          ]
        }
      ]
    }
  ]
}